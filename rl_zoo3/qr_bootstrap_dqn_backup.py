"""
QR-Bootstrap Hybrid DQN â€” ç»“åˆåˆ†ä½æ•°å›å½’å’ŒBootstrap ensembleçš„æ··åˆæ–¹æ³•
QR-Bootstrap Hybrid DQN â€” Combining quantile regression with bootstrap ensemble
----------------------------------------------------------------------------------
âœ“ åŒåˆ†æ”¯æ¶æ„: QRåˆ†æ”¯(åˆ†ä½æ•°é¢„æµ‹) + Bootstrapåˆ†æ”¯(ensembleé¢„æµ‹)
âœ“ è‡ªé€‚åº”æƒé‡èåˆ: å­¦ä¹ QRå’ŒBootstrapçš„æœ€ä¼˜ç»“åˆæƒé‡
âœ“ æ··åˆæŸå¤±å‡½æ•°: Quantile Loss + Ensemble Loss + Consistency Loss
âœ“ å…¼å®¹SB3æ¡†æ¶: åŸºäºç°æœ‰BootstrappedDQNå’ŒQR-DQNæ‰©å±•
"""

from __future__ import annotations
from typing import List, Optional, NamedTuple, Dict, Any
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import gymnasium as gym

from stable_baselines3.dqn import DQN
from stable_baselines3.dqn.policies import DQNPolicy
from stable_baselines3.common.buffers import ReplayBuffer
from stable_baselines3.common.torch_layers import FlattenExtractor
from stable_baselines3.common.utils import polyak_update

# å¤ç”¨ç°æœ‰çš„BootstrapåŸºç¡€è®¾æ–½
from .bootstrapped_dqn import BootstrappedSamples, BootstrapMaskBuffer


class QRBootstrapNetwork(nn.Module):
    """
    QR-Bootstrapæ··åˆç½‘ç»œ
    ç»“åˆQR-DQNçš„åˆ†ä½æ•°é¢„æµ‹å’ŒBootstrappedDQNçš„ensembleç»“æ„
    """
    
    def __init__(
        self,
        observation_space: gym.Space,
        action_space: gym.Space,
        n_quantiles: int = 51,
        n_bootstrap_heads: int = 5,
        features_extractor_class=FlattenExtractor,
        features_extractor_kwargs: Optional[Dict[str, Any]] = None,
        normalize_images: bool = True,
    ):
        super().__init__()
        
        self.observation_space = observation_space
        self.action_space = action_space
        self.n_quantiles = n_quantiles
        self.n_bootstrap_heads = n_bootstrap_heads
        self.n_actions = action_space.n
        
        # ç‰¹å¾æå–å™¨
        if features_extractor_kwargs is None:
            features_extractor_kwargs = {}
        
        self.features_extractor = features_extractor_class(
            observation_space, **features_extractor_kwargs
        )
        
        # å…±äº«ç‰¹å¾å±‚
        self.shared_net = nn.Sequential(
            nn.Linear(self.features_extractor.features_dim, 256),
            nn.ReLU(),
            nn.Linear(256, 256),
            nn.ReLU(),
        )
        
        # QRåˆ†æ”¯: é¢„æµ‹åˆ†ä½æ•°åˆ†å¸ƒ [batch, n_actions, n_quantiles]
        self.qr_head = nn.Linear(256, self.n_actions * self.n_quantiles)
        
        # Bootstrapåˆ†æ”¯: å¤šä¸ªç‹¬ç«‹Qå¤´ [batch, n_actions, n_heads] 
        self.bootstrap_heads = nn.ModuleList([
            nn.Linear(256, self.n_actions) for _ in range(n_bootstrap_heads)
        ])
        
        # è‡ªé€‚åº”èåˆå±‚: å­¦ä¹ QRå’ŒBootstrapçš„æƒé‡
        self.fusion_net = nn.Sequential(
            nn.Linear(256, 64),
            nn.ReLU(),
            nn.Linear(64, 2),
            nn.Softmax(dim=-1)  # ç¡®ä¿æƒé‡å’Œä¸º1
        )
        
        # åˆ†ä½æ•°çº§åˆ« (1%-99%)
        quantile_levels = torch.linspace(0.01, 0.99, n_quantiles)
        self.register_buffer('quantile_levels', quantile_levels)
    
    def forward(self, observations: torch.Tensor) -> Dict[str, torch.Tensor]:
        """
        å‰å‘ä¼ æ’­: åŒæ—¶è¾“å‡ºQRåˆ†ä½æ•°å’ŒBootstrap ensemble
        """
        # ç‰¹å¾æå–
        features = self.features_extractor(observations)
        shared_features = self.shared_net(features)
        
        # QRåˆ†æ”¯é¢„æµ‹
        qr_outputs = self.qr_head(shared_features)
        qr_quantiles = qr_outputs.view(-1, self.n_actions, self.n_quantiles)
        
        # Bootstrapåˆ†æ”¯é¢„æµ‹
        bootstrap_outputs = []
        for head in self.bootstrap_heads:
            head_q = head(shared_features)
            bootstrap_outputs.append(head_q)
        bootstrap_ensemble = torch.stack(bootstrap_outputs, dim=-1)  # [batch, n_actions, n_heads]
        
        # è‡ªé€‚åº”èåˆæƒé‡
        fusion_weights = self.fusion_net(shared_features)  # [batch, 2]
        qr_weight = fusion_weights[:, 0:1]  # [batch, 1]
        bootstrap_weight = fusion_weights[:, 1:2]  # [batch, 1]
        
        return {
            'qr_quantiles': qr_quantiles,
            'bootstrap_ensemble': bootstrap_ensemble,
            'fusion_weights': fusion_weights,
            'qr_weight': qr_weight,
            'bootstrap_weight': bootstrap_weight,
            'shared_features': shared_features
        }
    
    def get_q_values(self, observations: torch.Tensor) -> torch.Tensor:
        """
        è·å–Qå€¼ (ç”¨äºaction selection)
        ä½¿ç”¨èåˆåçš„æœŸæœ›å€¼ä½œä¸ºQå€¼ä¼°è®¡
        """
        outputs = self.forward(observations)
        
        # QRåˆ†æ”¯çš„æœŸæœ›Qå€¼
        qr_q_values = torch.mean(outputs['qr_quantiles'], dim=-1)  # [batch, n_actions]
        
        # Bootstrapåˆ†æ”¯çš„æœŸæœ›Qå€¼
        bootstrap_q_values = torch.mean(outputs['bootstrap_ensemble'], dim=-1)  # [batch, n_actions]
        
        # èåˆQå€¼
        qr_weight = outputs['qr_weight']  # [batch, 1]
        bootstrap_weight = outputs['bootstrap_weight']  # [batch, 1]
        
        fused_q_values = qr_weight * qr_q_values + bootstrap_weight * bootstrap_q_values
        
        return fused_q_values
    
    def get_uncertainty_estimates(self, observations: torch.Tensor, actions: torch.Tensor) -> Dict[str, torch.Tensor]:
        """
        è·å–æ··åˆä¸ç¡®å®šæ€§ä¼°è®¡
        """
        outputs = self.forward(observations)
        batch_size = observations.size(0)
        
        # æå–æŒ‡å®šactionçš„é¢„æµ‹
        action_indices = actions.long().unsqueeze(-1)  # [batch, 1]
        
        # QRåˆ†æ”¯çš„ä¸ç¡®å®šæ€§
        qr_quantiles_selected = torch.gather(
            outputs['qr_quantiles'], 1, 
            action_indices.unsqueeze(-1).expand(-1, -1, self.n_quantiles)
        ).squeeze(1)  # [batch, n_quantiles]
        
        qr_mean = torch.mean(qr_quantiles_selected, dim=-1)
        qr_std = torch.std(qr_quantiles_selected, dim=-1)
        
        # Bootstrapåˆ†æ”¯çš„ä¸ç¡®å®šæ€§
        bootstrap_values_selected = torch.gather(
            outputs['bootstrap_ensemble'], 1,
            action_indices.unsqueeze(-1).expand(-1, -1, self.n_bootstrap_heads)
        ).squeeze(1)  # [batch, n_heads]
        
        bootstrap_mean = torch.mean(bootstrap_values_selected, dim=-1)
        bootstrap_std = torch.std(bootstrap_values_selected, dim=-1)
        
        # èåˆä¸ç¡®å®šæ€§
        qr_weight = outputs['qr_weight'].squeeze()  # [batch]
        bootstrap_weight = outputs['bootstrap_weight'].squeeze()  # [batch]
        
        fused_mean = qr_weight * qr_mean + bootstrap_weight * bootstrap_mean
        fused_std = torch.sqrt(
            qr_weight**2 * qr_std**2 + bootstrap_weight**2 * bootstrap_std**2
        )
        
        return {
            'fused_mean': fused_mean,
            'fused_std': fused_std,
            'qr_mean': qr_mean,
            'qr_std': qr_std,
            'bootstrap_mean': bootstrap_mean,
            'bootstrap_std': bootstrap_std,
            'qr_weight': qr_weight,
            'bootstrap_weight': bootstrap_weight,
            'qr_quantiles': qr_quantiles_selected,
            'bootstrap_ensemble': bootstrap_values_selected
        }


class QRBootstrapPolicy(DQNPolicy):
    """
    QR-Bootstrapæ··åˆç­–ç•¥
    """
    
    def __init__(
        self,
        observation_space: gym.Space,
        action_space: gym.Space,
        lr_schedule,
        n_quantiles: int = 51,
        n_bootstrap_heads: int = 5,
        **kwargs
    ):
        self.n_quantiles = n_quantiles
        self.n_bootstrap_heads = n_bootstrap_heads
        
        # è®¾ç½®ç½‘ç»œå‚æ•°
        if "net_arch" not in kwargs:
            kwargs["net_arch"] = [256, 256]
        
        super().__init__(observation_space, action_space, lr_schedule, **kwargs)
    
    def make_q_net(self) -> QRBootstrapNetwork:
        """åˆ›å»ºQç½‘ç»œ"""
        return QRBootstrapNetwork(
            self.observation_space,
            self.action_space,
            n_quantiles=self.n_quantiles,
            n_bootstrap_heads=self.n_bootstrap_heads,
            features_extractor_class=self.features_extractor_class,
            features_extractor_kwargs=self.features_extractor_kwargs,
        )
    
    def forward(self, obs: torch.Tensor, deterministic: bool = True) -> torch.Tensor:
        """å‰å‘ä¼ æ’­ç”¨äºaction selection"""
        q_values = self.q_net.get_q_values(obs)
        return q_values
    
    def _predict(self, observation: torch.Tensor, deterministic: bool = True) -> torch.Tensor:
        """é¢„æµ‹åŠ¨ä½œ"""
        q_values = self.q_net.get_q_values(observation)
        action = q_values.argmax(dim=1).reshape(-1)
        return action


class QRBootstrapDQN(DQN):
    """
    QR-Bootstrapæ··åˆDQNç®—æ³•
    """
    
    policy: QRBootstrapPolicy
    
    def __init__(
        self,
        policy="QRBootstrapPolicy",
        env=None,
        n_quantiles: int = 51,
        n_bootstrap_heads: int = 5,
        qr_loss_weight: float = 1.0,
        bootstrap_loss_weight: float = 1.0,
        consistency_loss_weight: float = 0.1,
        fusion_regularization_weight: float = 0.01,
        **kwargs
    ):
        self.n_quantiles = n_quantiles
        self.n_bootstrap_heads = n_bootstrap_heads
        self.qr_loss_weight = qr_loss_weight
        self.bootstrap_loss_weight = bootstrap_loss_weight
        self.consistency_loss_weight = consistency_loss_weight
        self.fusion_regularization_weight = fusion_regularization_weight
        
        # è®¾ç½®policyå‚æ•°
        if "policy_kwargs" not in kwargs:
            kwargs["policy_kwargs"] = {}
        kwargs["policy_kwargs"]["n_quantiles"] = n_quantiles
        kwargs["policy_kwargs"]["n_bootstrap_heads"] = n_bootstrap_heads
        
        # ä½¿ç”¨Bootstrap mask buffer
        kwargs["replay_buffer_class"] = BootstrapMaskBuffer
        kwargs["replay_buffer_kwargs"] = {
            "n_heads": n_bootstrap_heads,
            **(kwargs.get("replay_buffer_kwargs", {}))
        }
        
        super().__init__(policy=policy, env=env, **kwargs)
        
        # æ³¨å†Œåˆ†ä½æ•°çº§åˆ«
        quantile_levels = torch.linspace(0.01, 0.99, n_quantiles)
        self.register_buffer('quantile_levels', quantile_levels)
    
    def train(self, gradient_steps: int, batch_size: int = 100) -> None:
        """è®­ç»ƒç½‘ç»œ"""
        losses = []
        
        for _ in range(gradient_steps):
            # ä»ç»éªŒæ± ä¸­é‡‡æ · (åŒ…å«bootstrap mask)
            replay_data = self.replay_buffer.sample(batch_size, env=self._vec_normalize_env)
            
            # è®¡ç®—æ··åˆæŸå¤±
            loss_dict = self._compute_hybrid_loss(replay_data)
            loss = loss_dict['total_loss']
            
            # æ¢¯åº¦æ›´æ–°
            self.policy.optimizer.zero_grad()
            loss.backward()
            torch.nn.utils.clip_grad_norm_(self.policy.parameters(), self.max_grad_norm)
            self.policy.optimizer.step()
            
            losses.append(loss.item())
        
        # æ›´æ–°target network
        polyak_update(self.q_net.parameters(), self.q_net_target.parameters(), self.tau)
        
        # è®°å½•è®­ç»ƒç»Ÿè®¡
        self.logger.record("train/loss", np.mean(losses))
    
    def _compute_hybrid_loss(self, replay_data: BootstrappedSamples) -> Dict[str, torch.Tensor]:
        """è®¡ç®—æ··åˆæŸå¤±å‡½æ•°"""
        with torch.no_grad():
            # ç›®æ ‡å€¼è®¡ç®— (ä½¿ç”¨target network)
            next_q_values = self.q_net_target.get_q_values(replay_data.next_observations)
            next_q_values, _ = torch.max(next_q_values, dim=1)
            target_q_values = replay_data.rewards + (1 - replay_data.dones) * self.gamma * next_q_values
        
        # å½“å‰ç½‘ç»œé¢„æµ‹
        current_outputs = self.q_net.forward(replay_data.observations)
        
        # æå–é€‰å®šactionçš„é¢„æµ‹
        actions = replay_data.actions.long()
        action_indices = actions.unsqueeze(-1)
        
        # QRåˆ†æ”¯æŸå¤±: Quantile Regression Loss
        current_qr_quantiles = torch.gather(
            current_outputs['qr_quantiles'], 1,
            action_indices.unsqueeze(-1).expand(-1, -1, self.n_quantiles)
        ).squeeze(1)  # [batch, n_quantiles]
        
        target_expanded = target_q_values.unsqueeze(-1).expand(-1, self.n_quantiles)
        quantile_errors = target_expanded - current_qr_quantiles
        quantile_losses = torch.max(
            self.quantile_levels * quantile_errors,
            (self.quantile_levels - 1) * quantile_errors
        )
        qr_loss = quantile_losses.mean()
        
        # Bootstrapåˆ†æ”¯æŸå¤±: Masked Ensemble MSE Loss
        bootstrap_losses = []
        for head_idx in range(self.n_bootstrap_heads):
            head_q_values = current_outputs['bootstrap_ensemble'][:, :, head_idx]
            head_selected = torch.gather(head_q_values, 1, action_indices).squeeze(1)
            
            # ä½¿ç”¨bootstrap mask
            mask = replay_data.mask[:, head_idx]
            masked_loss = F.mse_loss(head_selected * mask, target_q_values * mask, reduction='none')
            bootstrap_losses.append(masked_loss.mean())
        
        bootstrap_loss = torch.stack(bootstrap_losses).mean()
        
        # ä¸€è‡´æ€§æŸå¤±: QRå’ŒBootstrapé¢„æµ‹çš„ä¸€è‡´æ€§
        qr_mean_q = torch.mean(current_qr_quantiles, dim=-1)
        bootstrap_mean_q = torch.gather(
            torch.mean(current_outputs['bootstrap_ensemble'], dim=-1), 1, action_indices
        ).squeeze(1)
        consistency_loss = F.mse_loss(qr_mean_q, bootstrap_mean_q)
        
        # èåˆæƒé‡æ­£åˆ™åŒ–: é¿å…ä¸€ä¸ªåˆ†æ”¯å®Œå…¨ä¸»å¯¼
        fusion_weights = current_outputs['fusion_weights']
        # é¼“åŠ±æƒé‡æ¥è¿‘å‡åŒ€åˆ†å¸ƒ [0.5, 0.5]
        target_weights = torch.full_like(fusion_weights, 0.5)
        fusion_regularization = F.mse_loss(fusion_weights, target_weights)
        
        # æ€»æŸå¤±
        total_loss = (self.qr_loss_weight * qr_loss + 
                     self.bootstrap_loss_weight * bootstrap_loss + 
                     self.consistency_loss_weight * consistency_loss + 
                     self.fusion_regularization_weight * fusion_regularization)
        
        return {
            'total_loss': total_loss,
            'qr_loss': qr_loss,
            'bootstrap_loss': bootstrap_loss,
            'consistency_loss': consistency_loss,
            'fusion_regularization': fusion_regularization
        }
    
    @property  
    def q_net(self) -> QRBootstrapNetwork:
        """å½“å‰Qç½‘ç»œ"""
        return self.policy.q_net
    
    @property
    def q_net_target(self) -> QRBootstrapNetwork:
        """ç›®æ ‡Qç½‘ç»œ"""
        return self.policy.q_net_target
    
    def register_buffer(self, name: str, tensor: torch.Tensor):
        """æ³¨å†Œbufferåˆ°è®¾å¤‡"""
        if not hasattr(self, '_buffers'):
            self._buffers = {}
        self._buffers[name] = tensor.to(self.device)


# QRBootstrapPolicyå’ŒQRBootstrapDQNç±»å·²ç»åœ¨ä¸Šé¢å®šä¹‰ï¼Œæ— éœ€é¢å¤–æ³¨å†Œå‡½æ•°


if __name__ == "__main__":
    # æµ‹è¯•æ··åˆç½‘ç»œ
    import gymnasium as gym
    
    env = gym.make("CartPole-v1")
    
    # åˆ›å»ºæ··åˆç½‘ç»œ
    network = QRBootstrapNetwork(
        observation_space=env.observation_space,
        action_space=env.action_space,
        n_quantiles=51,
        n_bootstrap_heads=5
    )
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    obs = torch.randn(32, 4)  # batch_size=32
    outputs = network.forward(obs)
    
    print("ğŸ§ª QR-Bootstrapç½‘ç»œæµ‹è¯•:")
    print(f"  QR quantiles shape: {outputs['qr_quantiles'].shape}")
    print(f"  Bootstrap ensemble shape: {outputs['bootstrap_ensemble'].shape}")
    print(f"  Fusion weights shape: {outputs['fusion_weights'].shape}")
    print(f"âœ… ç½‘ç»œæ¶æ„éªŒè¯é€šè¿‡!")
    
    # æµ‹è¯•Qå€¼è®¡ç®—
    q_values = network.get_q_values(obs)
    print(f"  Q values shape: {q_values.shape}")
    
    # æµ‹è¯•ä¸ç¡®å®šæ€§ä¼°è®¡
    actions = torch.randint(0, 2, (32,))
    uncertainty = network.get_uncertainty_estimates(obs, actions)
    print(f"  Uncertainty keys: {list(uncertainty.keys())}")
    print(f"âœ… æ··åˆæ–¹æ³•å®ç°å®Œæˆ!")