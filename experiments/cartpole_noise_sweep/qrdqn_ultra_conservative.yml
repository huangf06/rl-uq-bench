# QR-DQN 超保守版本 - 极其稳定的噪声环境配置
# 策略: 极低学习率 + 超长训练 + 大网络 + 保守exploration

CartPole-v1:
  n_timesteps: !!float 3e5        # 延长到30万步
  policy: 'MlpPolicy'
  learning_rate: !!float 1e-4      # 极低学习率
  batch_size: 32                   # 小batch保证稳定性
  buffer_size: 200000              # 大buffer
  learning_starts: 5000            # 延迟开始学习
  gamma: 0.99
  target_update_interval: 50       # 更频繁的target更新
  train_freq: 32                   # 更频繁的训练
  gradient_steps: 16               # 保守的梯度步数
  exploration_fraction: 0.5        # 长时间exploration
  exploration_final_eps: 0.01      # 极小的final epsilon
  policy_kwargs: "dict(net_arch=[512, 512, 256], n_quantiles=20)"  # 大网络
  experiment_note: "ultra_conservative_noise_0.025"
  noise_wrapper:
    name: GaussianObsNoise
    kwargs:
      noise_std: 0.025             # 减少噪声强度
      clip: true
      inplace: false